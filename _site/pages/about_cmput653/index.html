<!DOCTYPE html> <html lang="en-US"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="/2024/assets/css/just-the-docs-default.css"> <script src="/2024/assets/js/vendor/lunr.min.js"></script> <script src="/2024/assets/js/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <link rel="icon" href="/2024/favicon.ico" type="image/x-icon"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>About CMPUT 653 (OLD) | RL Theory</title> <meta name="generator" content="Jekyll v4.2.2" /> <meta property="og:title" content="About CMPUT 653 (OLD)" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="CMPUT 653: Theoretical Foundations of Reinforcement Learning W2022" /> <meta property="og:description" content="CMPUT 653: Theoretical Foundations of Reinforcement Learning W2022" /> <link rel="canonical" href="http://localhost:4000/2024/pages/about_cmput653/" /> <meta property="og:url" content="http://localhost:4000/2024/pages/about_cmput653/" /> <meta property="og:site_name" content="RL Theory" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2024-09-21T14:43:24-06:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="About CMPUT 653 (OLD)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-09-21T14:43:24-06:00","datePublished":"2024-09-21T14:43:24-06:00","description":"CMPUT 653: Theoretical Foundations of Reinforcement Learning W2022","headline":"About CMPUT 653 (OLD)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2024/pages/about_cmput653/"},"url":"http://localhost:4000/2024/pages/about_cmput653/"}</script> <!-- End Jekyll SEO tag --> <!-- MathJax --> <!-- http://docs.mathjax.org/en/latest/web/start.html --> <!-- http://docs.mathjax.org/en/latest/web/configuration.html#web-configuration --> <!-- http://docs.mathjax.org/en/latest/options/input/tex.html --> <!-- http://docs.mathjax.org/en/latest/input/tex/eqnumbers.html --> <script> MathJax = { tex: { inlineMath: [['$', '$'], ['\\(', '\\)']], processEscapes: true, tags: 'ams' } }; </script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <!-- Google fonts --> <!-- https://fonts.google.com/specimen/Merriweather?sidebar.open=true&selection.family=Merriweather:wght@400;900 --> <style> @import url('https://fonts.googleapis.com/css2?family=Merriweather:wght@400;900&display=swap'); </style> </head> <body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header"> <a href="http://localhost:4000/2024/" class="site-title lh-tight"> RL Theory </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a> </div> <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"> <div class="nav-category">Pages</div> <ul class="nav-list"><li class="nav-list-item"><a href="/2024/" class="nav-list-link">Home</a></li><li class="nav-list-item"><a href="/2024/pages/about/" class="nav-list-link">About CMPUT 605</a></li><li class="nav-list-item"><a href="/2024/pages/about_cmput653/" class="nav-list-link active">About CMPUT 653 (OLD)</a></li><li class="nav-list-item"><a href="/2024/pages/lectures/" class="nav-list-link">Lectures</a></li><li class="nav-list-item"><a href="/2024/pages/assignments/" class="nav-list-link">The work you do</a></li></ul> <div class="nav-category">Lecture Notes</div> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Planning in MDPs category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/2024/lecture-notes/planning-in-mdps" class="nav-list-link">Planning in MDPs</a><ul class="nav-list"><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec1/" class="nav-list-link">1. Introductions</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec2/" class="nav-list-link">2. The Fundamental Theorem</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec3/" class="nav-list-link">3. Value Iteration and Our First Lower Bound</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec4/" class="nav-list-link">4. Policy Iteration</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec5/" class="nav-list-link">5. Online Planning - Part I.</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec6/" class="nav-list-link">6. online planning - Part II.</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec7/" class="nav-list-link">7. Function Approximation</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec8/" class="nav-list-link">8. Approximate Policy Iteration</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec9/" class="nav-list-link">9. Limits of query-efficient planning</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec10/" class="nav-list-link">10. Planning under $q^*$ realizability</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec11/" class="nav-list-link">11. Planning under $v^*$ realizability (TensorPlan I.)</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec12/" class="nav-list-link">12. TensorPlan and eluder sequences</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec13/" class="nav-list-link">13. From API to Politex</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec14/" class="nav-list-link">14. Politex</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec15/" class="nav-list-link">15. From policy search to policy gradients</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/planning-in-mdps/lec16/" class="nav-list-link">16. Policy gradients</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Online RL category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/2024/lecture-notes/online-rl" class="nav-list-link">Online RL</a><ul class="nav-list"><li class="nav-list-item "><a href="/2024/lecture-notes/online-rl/lec22/" class="nav-list-link">22. Introduction</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/online-rl/lec23/" class="nav-list-link">23. Tabular MDPs</a></li><li class="nav-list-item "><a href="/2024/lecture-notes/online-rl/lec24/" class="nav-list-link">24. Featurized MDPs</a></li></ul></li></ul> <div class="nav-category">Winter 2022 Lecture Notes</div> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Planning in MDPs category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/2024/w2022-lecture-notes/planning-in-mdps" class="nav-list-link">Planning in MDPs</a><ul class="nav-list"><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec1/" class="nav-list-link">1. Introductions</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec2/" class="nav-list-link">2. The Fundamental Theorem</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec3/" class="nav-list-link">3. Value Iteration and Our First Lower Bound</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec4/" class="nav-list-link">4. Policy Iteration</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec5/" class="nav-list-link">5. Online Planning - Part I.</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec6/" class="nav-list-link">6. online planning - Part II.</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec7/" class="nav-list-link">7. Function Approximation</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec8/" class="nav-list-link">8. Approximate Policy Iteration</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec9/" class="nav-list-link">9. Limits of query-efficient planning</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec10/" class="nav-list-link">10. Planning under $q^*$ realizability</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec11/" class="nav-list-link">11. Planning under $v^*$ realizability (TensorPlan I.)</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec12/" class="nav-list-link">12. TensorPlan and eluder sequences</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec13/" class="nav-list-link">13. From API to Politex</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec14/" class="nav-list-link">14. Politex</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec15/" class="nav-list-link">15. From policy search to policy gradients</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/planning-in-mdps/lec16/" class="nav-list-link">16. Policy gradients</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Batch RL category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/2024/w2022-lecture-notes/batch-rl" class="nav-list-link">Batch RL</a><ul class="nav-list"><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/batch-rl/lec17/" class="nav-list-link">17. Introduction</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/batch-rl/lec18/" class="nav-list-link">18. Sample complexity in finite MDPs</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/batch-rl/lec19/" class="nav-list-link">19. Scaling with value function approximation</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Online RL category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/2024/w2022-lecture-notes/online-rl" class="nav-list-link">Online RL</a><ul class="nav-list"><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/online-rl/lec22/" class="nav-list-link">22. Introduction</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/online-rl/lec23/" class="nav-list-link">23. Tabular MDPs</a></li><li class="nav-list-item "><a href="/2024/w2022-lecture-notes/online-rl/lec24/" class="nav-list-link">24. Featurized MDPs</a></li></ul></li></ul> <div class="nav-category">Winter 2021 Lecture Notes</div> <ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Planning in MDPs category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/2024/w2021-lecture-notes/planning-in-mdps" class="nav-list-link">Planning in MDPs</a><ul class="nav-list"><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec1/" class="nav-list-link">1. Introductions</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec2/" class="nav-list-link">2. The Fundamental Theorem</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec3/" class="nav-list-link">3. Value Iteration and Our First Lower Bound</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec4/" class="nav-list-link">4. Policy Iteration</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec5/" class="nav-list-link">5. Local Planning - Part I.</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec6/" class="nav-list-link">6. Local Planning - Part II.</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec7/" class="nav-list-link">7. Function Approximation</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec8/" class="nav-list-link">8. Approximate Policy Iteration</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec9/" class="nav-list-link">9. Limits of query-efficient planning</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec10/" class="nav-list-link">10. Planning under $q^*$ realizability</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec11/" class="nav-list-link">11. Planning under $v^*$ realizability (TensorPlan I.)</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec12/" class="nav-list-link">12. TensorPlan and eluder sequences</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec13/" class="nav-list-link">13. From API to Politex</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec14/" class="nav-list-link">14. Politex</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec15/" class="nav-list-link">15. From policy search to policy gradients</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/planning-in-mdps/lec16/" class="nav-list-link">16. Policy gradients</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Batch RL category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/2024/w2021-lecture-notes/batch-rl" class="nav-list-link">Batch RL</a><ul class="nav-list"><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/batch-rl/lec17/" class="nav-list-link">17. Introduction</a></li><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/batch-rl/lec18/" class="nav-list-link">18. Sample complexity in finite MDPs</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Online RL category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/2024/w2021-lecture-notes/online-rl" class="nav-list-link">Online RL</a><ul class="nav-list"><li class="nav-list-item "><a href="/2024/w2021-lecture-notes/online-rl/blank/" class="nav-list-link">Blank</a></li></ul></li></ul> </nav> <footer class="site-footer"> Website of the course CMPUT 653: Theoretical Foundations of Reinforcement Learning. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search RL Theory" aria-label="Search RL Theory" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> </div> <div id="main-content-wrap" class="main-content-wrap"> <div id="main-content" class="main-content" role="main"> <h1 id="cmput-653-theoretical-foundations-of-reinforcement-learning-w2022">CMPUT 653: Theoretical Foundations of Reinforcement Learning W2022</h1> <p>The purpose of this course is to let students acquire a solid understanding of the theoretical foundations of reinforcement learning, as well as to give students a glimpse on what theoretical research looks like in the context of computer science. The topics will range from building up foundations (Markovian Decision Processes and the various special cases of it), to discussing solutions to the three core problem settings:</p> <ul> <li><a href="/lecture-notes/planning-in-mdps">planning/simulation optimization</a></li> <li><a href="/lecture-notes/batch-rl">batch reinforcement learning</a>, and</li> <li><a href="/lecture-notes/online-rl">online reinforcement learning</a></li> </ul> <p>In each of these settings, we cover key algorithmic challenges and the core ideas to address these. Specific topics, ideas and algorithms covered include, for each topic:</p> <ul> <li>complexity of planning/simulation optimization; large scale planning with function approximation;</li> <li>sample complexity of batch learning with and without function approximation;</li> <li>efficient online learning: the role (and limits) of optimism; scaling up with function approximation.</li> </ul> <p>While we will explore connection to (some) deep RL methods, mainly seeking an answer to the question of when can we expect them to work well, the course will <em>not</em> focus on deep RL.</p> <h2 id="pre-requisites">Pre-requisites</h2> <p>Students taking the course are expected to have an understanding of basic probability, basics of concentration inequalities, linear algebra and convex optimization. This background is covered in Chapters 2, 3, 5, 7, 26, and 38 of the <a href="https://tor-lattimore.com/downloads/book/book.pdf">Bandit Algorithms book</a>. One very nice book that covers more, but is still highly recommended is <a href="http://people.bu.edu/pekoz/A_Second_Course_in_Probability-Ross-Pekoz.pdf">A Second Course in Probability Theory</a>. The book is available online and also in book format. Chapters 1, 3, 4, and 5 are most useful from here.</p> <p>It will also be useful to recall foundations of mathematical analysis, such as completeness, metric spaces and alike, as we will start off with results that will require Banach’s fixed point theorem. This is covered, for example, in Appendix A of <a href="https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf">Csaba’s “little” RL book</a>. The <a href="https://en.wikipedia.org/wiki/Banach_fixed-point_theorem">wikipedia page</a> on Banach’s fixed point theorem is not that bad either.</p> <h2 id="instruction-team">Instruction Team</h2> <ul> <li><a href="https://sites.ualberta.ca/~szepesva">Csaba Szepesvári</a></li> <li><a href="mailto:aayoub@ualberta.ca">Alex Ayoub</a></li> <li><a href="mailto:vtkachuk@ualberta.ca">Vlad Tkachuk</a></li> </ul> <h2 id="lecture-time-recordings-here">Lecture Time (recordings <a href="/pages/lectures">here</a>)</h2> <p>Monday and Wednesdays from 2:00 PM - 3:20 PM (MST).</p> <p>The first three weeks will be online only and the format will be that of a flipped class. For the rest (Jan 25 and later), we aim for traditional, in-person lectures with chalk-board talks. The room is GSB 5-53</p> <h2 id="eclass">eClass</h2> <p>We will use eclass for assignment submissions. The link to join eClass can be found <a href="https://eclass.srv.ualberta.ca/course/view.php?id=76687">here</a>. We will not use eClass for announcements and discussions. For these we will use Slack.</p> <h2 id="slack-channel">Slack Channel</h2> <p>We have a channel called <code class="language-plaintext highlighter-rouge">#cmput653-discussion-w2022</code> on the Amii slack to discuss all topics related to this course. This channel is open to anyone who is on Amii slack. If you are already a part of the Amii slack, feel free to join this channel. For discussions related to marking, assignment schedule, etc. we have a second channel <code class="language-plaintext highlighter-rouge">#cmput653-private-discussion-w2022</code>, which is by invitation only. The TAs will add anyone who is taking the course for credit to these slack channels. All announcements will be made on <code class="language-plaintext highlighter-rouge">#cmput653-discussion-w2022</code>.</p> <h2 id="google-meet-information">Google Meet Information</h2> <p>The google meet information will be posted on the slack channel and on eClass. This is relevant up to the point when teaching becomes in-person.</p> <h2 id="grading-policies">Grading Policies</h2> <p>Can be found on <a href="https://eclass.srv.ualberta.ca/course/view.php?id=76687">eClass</a>.</p> <h2 id="lectures-notes">Lectures Notes</h2> <p>Lecture notes of last year’s class is available on this site. The lecture notes for this year’s class starts from this, but may be modified. The lecture notes serve as the required text for this course.</p> <h2 id="flipped-class">Flipped Class</h2> <p>For the first three weeks, as mentioned above, we will follow a flipped class format: Students coming to class are required to</p> <ul> <li>read the associated lecture notes and/or watch the lecture recordings</li> <li>prepare and vote on questions on the slack discussion channel</li> </ul> <p>In class time will be spent on a</p> <ul> <li>quick review of the material</li> <li>discussing the most voted questions</li> <li>small group discussions of various topics</li> </ul> <p><strong>Keywords:</strong> RL theory, Reinforcement Learning, Theoretical Reinforcement Learning</p> <hr> <footer> <p><a href="#top" id="back-to-top">Back to top</a></p> <p class="text-small text-grey-dk-100 mb-0">Copyright &copy; 2024 RL Theory.</p> <div class="d-flex mt-2"> </div> </footer> </div> </div> <div class="search-overlay"></div> </div> </body> </html>
